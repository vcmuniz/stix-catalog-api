# ğŸ“š Catalog API - Product Management Backend

Uma API REST robusta para gerenciamento de catÃ¡logo de produtos, construÃ­da com **NestJS**, **CQRS**, **DDD** e **Apache Kafka**.

## ğŸ¯ CaracterÃ­sticas

- âœ… **CQRS + DDD**: SeparaÃ§Ã£o clara entre lÃ³gica de escrita e leitura
- âœ… **Event Sourcing**: Kafka para auditoria e event streaming
- âœ… **PostgreSQL + TypeORM**: PersistÃªncia com migraÃ§Ãµes
- âœ… **Logs Estruturados**: Winston com JSON
- âœ… **Swagger/OpenAPI**: DocumentaÃ§Ã£o interativa
- âœ… **Health Check**: VerificaÃ§Ã£o de saÃºde
- âœ… **ValidaÃ§Ãµes de Regras de NegÃ³cio**: Centralizadas

## ğŸš€ Quick Start

### PrÃ©-requisitos
- Node.js >= 18
- Docker & Docker Compose

### InstalaÃ§Ã£o

```bash
# 1. Instale dependÃªncias
npm install

# 2. Inicie serviÃ§os
docker-compose up -d

# 3. Aguarde 15s e inicie app
npm run start:dev
```

âœ… API: http://localhost:3000  
ğŸ“š Swagger: http://localhost:3000/api/docs  
ğŸ¥ Health: http://localhost:3000/health

## ğŸ“– Endpoints Principais

### Categorias
```bash
POST   /categories              # Criar
GET    /categories              # Listar
GET    /categories/:id          # Detalhes
PUT    /categories/:id          # Atualizar
```

### Produtos
```bash
POST   /products                           # Criar
GET    /products                           # Listar
GET    /products/:id                       # Detalhes
POST   /products/:id/activate              # Ativar
POST   /products/:id/archive               # Arquivar
POST   /products/:id/categories/:catId     # Adicionar categoria
DELETE /products/:id/categories/:catId     # Remover categoria
POST   /products/:id/attributes            # Adicionar atributo
PUT    /products/:id/attributes/:key       # Atualizar atributo
DELETE /products/:id/attributes/:key       # Remover atributo
PUT    /products/:id/description           # Atualizar descriÃ§Ã£o
```

### Auditoria
```bash
GET    /audit-logs                         # Listar todas as auditrias
GET    /audit-logs/summary                 # Resumo de eventos
GET    /audit-logs/entity/:type/:id        # Auditoria de entidade especÃ­fica
GET    /audit-logs/event/:type             # Auditoria por tipo de evento
```

## ğŸ® Exemplo de Uso

```bash
# 1. Criar categoria
curl -X POST http://localhost:3000/categories \
  -H "Content-Type: application/json" \
  -d '{"name": "EletrÃ´nicos"}'

# 2. Criar produto
curl -X POST http://localhost:3000/products \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Laptop Dell",
    "categoryIds": ["<category-id>"],
    "attributes": [
      {"key": "cpu", "value": "Intel i7"},
      {"key": "ram", "value": "16GB"}
    ]
  }'

# 3. Ativar produto
curl -X POST http://localhost:3000/products/<product-id>/activate
```

## ğŸ—ï¸ Arquitetura

### PadrÃµes
- **CQRS**: Commands para escrita, Queries para leitura
- **DDD**: Domain Events, Aggregates, Business Rules
- **Event-Driven**: Kafka Producer + Event Subscribers

## ğŸ“Š Regras de NegÃ³cio

### Produtos
- Status: DRAFT â†’ ACTIVE â†’ ARCHIVED
- AtivaÃ§Ã£o requer: â‰¥1 categoria + â‰¥1 atributo + nome Ãºnico
- ARCHIVED nÃ£o pode voltar a ACTIVE
- ARCHIVED nÃ£o pode ter categorias/atributos modificados

### Categorias
- Nomes Ãºnicos
- Hierarquia com parentId
- Pai deve existir

### Atributos
- Keys Ãºnicas por produto
- Tipos: string, number, boolean

## ğŸ”§ VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto baseado em `.env.example`:

```env
# App
NODE_ENV=development
PORT=3000

# Database
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_USER=postgres
DATABASE_PASSWORD=postgres
DATABASE_NAME=catalog_db

# Kafka Producer
KAFKA_BROKERS=localhost:9092
KAFKA_CLIENT_ID=catalog-service
KAFKA_PRODUCER_TIMEOUT=10000

# Kafka Consumer (Audit)
KAFKA_CONSUMER_ID=catalog-audit-consumer
KAFKA_CONSUMER_GROUP=audit-service-group
KAFKA_CONSUMER_TIMEOUT=30000

# Logging
LOG_LEVEL=info
LOG_FORMAT=json
```

### Detalhes das VariÃ¡veis

#### App
| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `NODE_ENV` | Ambiente de execuÃ§Ã£o (`development`, `production`, `test`) | `development` |
| `PORT` | Porta HTTP onde a API serÃ¡ acessÃ­vel | `3000` |

#### Database
| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `DATABASE_HOST` | Host do servidor PostgreSQL | `localhost` |
| `DATABASE_PORT` | Porta do PostgreSQL | `5432` |
| `DATABASE_USER` | UsuÃ¡rio de acesso ao banco de dados | `postgres` |
| `DATABASE_PASSWORD` | Senha do usuÃ¡rio PostgreSQL | `postgres` |
| `DATABASE_NAME` | Nome do banco de dados a utilizar | `catalog_db` |

#### Kafka Producer
| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `KAFKA_BROKERS` | EndereÃ§o dos brokers Kafka (separados por vÃ­rgula se mÃºltiplos) | `localhost:9092` |
| `KAFKA_CLIENT_ID` | Identificador Ãºnico do cliente produtor Kafka | `catalog-service` |
| `KAFKA_PRODUCER_TIMEOUT` | Timeout em ms para enviar mensagens ao Kafka | `10000` |

#### Kafka Consumer (Audit)
| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `KAFKA_CONSUMER_ID` | Identificador Ãºnico do consumidor de auditoria | `catalog-audit-consumer` |
| `KAFKA_CONSUMER_GROUP` | Grupo de consumidores Kafka (permite mÃºltiplas instÃ¢ncias consumirem em paralelo) | `audit-service-group` |
| `KAFKA_CONSUMER_TIMEOUT` | Timeout em ms para processar mensagens do Kafka | `30000` |

#### Logging
| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `LOG_LEVEL` | NÃ­vel de log (`debug`, `info`, `warn`, `error`) | `info` |
| `LOG_FORMAT` | Formato de saÃ­da dos logs (`json`, `simple`) | `json` |

## ğŸ§ª Testes

```bash
npm run test              # UnitÃ¡rios
npm run test:e2e         # IntegraÃ§Ã£o
npm run test:cov         # Coverage
```

## ğŸ› ï¸ Scripts

```bash
npm run start:dev        # Dev mode
npm run build            # Build
npm run lint             # ESLint
npm run format           # Prettier
```

## ğŸ“ˆ Observabilidade

### Health Check
```bash
curl http://localhost:3000/health
```

### Auditoria via SQL
```sql
SELECT * FROM audit_logs 
WHERE entityType = 'Product'
ORDER BY createdAt DESC;
```

### Kafka Events (Monitor em Tempo Real)
```bash
docker exec -it catalog-kafka \
  kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic catalog.product.events \
  --from-beginning
```

## ğŸ“ DecisÃµes Arquiteturais (Resolvendo as Specs)

### Problema: Auditoria AssÃ­ncrona
**Spec:** "A aplicaÃ§Ã£o deve utilizar mensageria para processar auditoria de forma assÃ­ncrona"

**DecisÃ£o:** Kafka + Event Publishing Service + Async Consumer

**Por quÃª:**
- âœ… Eventos publicados **nÃ£o bloqueiam** requisiÃ§Ãµes do cliente
- âœ… Consumer processa auditoria **em background**
- âœ… Durabilidade: Se consumer cair, Kafka retem mensagens
- âœ… Escalabilidade: MÃºltiplos consumers podem processar eventos em paralelo

**Fluxo:**
1. Handler executa aÃ§Ã£o â†’ Publica evento para Kafka
2. Controller retorna resposta imediatamente (sÃ­ncrono)
3. Consumer consome e salva auditoria no BD (assÃ­ncrono)

### Problema: ValidaÃ§Ãµes Complexas de NegÃ³cio
**Spec:** Produtos com status DRAFT/ACTIVE/ARCHIVED, regras de transiÃ§Ã£o, atributos/categorias obrigatÃ³rias

**DecisÃ£o:** DDD + BusinessRules centralizadas

**Por quÃª:**
- âœ… Regras de negÃ³cio em um Ãºnico lugar (`ProductBusinessRules.ts`)
- âœ… ProteÃ§Ã£o contra estados invÃ¡lidos
- âœ… FÃ¡cil manutenÃ§Ã£o quando specs mudarem

**Exemplo:**
```typescript
// âŒ Sem DDD: ValidaÃ§Ã£o espalhada em Services
// âœ… Com DDD: Tudo centralizado
ProductBusinessRules.validateCanActivate(product.status, product.categories, product.attributes)
```

### Problema: MÃºltiplas OperaÃ§Ãµes CRUD + Consultas
**Spec:** Criar, atualizar, remover produtos/atributos/categorias + listar/filtrar

**DecisÃ£o:** CQRS (Commands para escrita, Queries para leitura)

**Por quÃª:**
- âœ… Commands (escrita) usam Handlers com validaÃ§Ã£o e eventos
- âœ… Queries (leitura) usam QueryHandlers otimizados
- âœ… IntenÃ§Ã£o explÃ­cita: Claro se Ã© operaÃ§Ã£o de escrita ou leitura
- âœ… Escalabilidade: Pode-se cachear Queries independente de Commands

**Exemplo:**
```typescript
// Command: Escrita com side effects (eventos)
CreateProductCommand â†’ CreateProductHandler â†’ Evento publicado

// Query: Leitura pura, sem side effects
GetProductByIdQuery â†’ GetProductHandler â†’ Sem eventos
```

### Problema: PersistÃªncia ConfiÃ¡vel com Relacionamentos
**Spec:** Produtos com categorias (many-to-many), atributos dinÃ¢micos, unicidade

**DecisÃ£o:** PostgreSQL + TypeORM + Migrations

**Por quÃª:**
- âœ… ACID: TransaÃ§Ãµes garantem integridade
- âœ… Foreign Keys: Impede produtos Ã³rfÃ£os
- âœ… Type-safe: TypeORM com decorators TS
- âœ… MigraÃ§Ãµes: HistÃ³rico de schema mudanÃ§as

---

## ğŸ“¡ EstratÃ©gia de Mensageria e Auditoria

### Arquitetura Event-Driven

```
AÃ§Ã£o no Produto/Categoria/Atributo
    â†“
Handler cria Domain Event
    â†“
EventPublishingService envia para Kafka
    â†“
Mensagem publicada em:
  - catalog.product.events (PRODUCT_*, ATTRIBUTE_*, CATEGORY_*_TO_PRODUCT)
  - catalog.category.events (CATEGORY_CREATED, CATEGORY_UPDATED)
    â†“
AuditLogConsumer consome mensagem
    â†“
Parse payload + Mapeia entityType
    â†“
Salva em audit_logs table
    â†“
API endpoints expÃµem auditoria
```

### Eventos Publicados (8 tipos)

**Produtos:**
- `PRODUCT_CREATED` - Quando produto Ã© criado
- `PRODUCT_ACTIVATED` - Quando produto passa para ACTIVE
- `PRODUCT_ARCHIVED` - Quando produto passa para ARCHIVED

**Categorias (em Produtos):**
- `CATEGORY_ADDED_TO_PRODUCT` - AssociaÃ§Ã£o
- `CATEGORY_REMOVED_FROM_PRODUCT` - DesassociaÃ§Ã£o

**Atributos:**
- `ATTRIBUTE_ADDED_TO_PRODUCT` - Novo atributo
- `ATTRIBUTE_UPDATED` - Valor do atributo mudou
- `ATTRIBUTE_REMOVED_FROM_PRODUCT` - Atributo removido

### Por que AssÃ­ncrono?

| RazÃ£o | Impacto |
|-------|--------|
| **NÃ£o bloqueia requisiÃ§Ã£o** | Client recebe resposta em ~50ms em vez de ~500ms |
| **EscalÃ¡vel** | Se consumer falhar, Kafka retÃ©m mensagens |
| **DurÃ¡vel** | Kafka persiste, nÃ£o perde eventos se processo cair |
| **RastreÃ¡vel** | Cada evento tem timestamp e payload completo |

### Consultando Auditoria

```bash
# API REST
curl http://localhost:3000/audit-logs
curl http://localhost:3000/audit-logs/summary
curl http://localhost:3000/audit-logs/entity/Product/<product-id>
curl http://localhost:3000/audit-logs/event/PRODUCT_CREATED

# Diretamente no BD
SELECT * FROM audit_logs WHERE eventType = 'PRODUCT_CREATED';

# Monitorando Kafka em tempo real
docker exec -it catalog-kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic catalog.product.events \
  --from-beginning
```

---

## ğŸ“ Estrutura

```
src/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ categories/    # CQRS + Eventos
â”‚   â”œâ”€â”€ products/      # CQRS + Eventos
â”‚   â”œâ”€â”€ audit/         # Audit logs
â”‚   â””â”€â”€ health/        # Health checks
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ logging/
â”‚   â”œâ”€â”€ events/        # Domain events
â”‚   â””â”€â”€ config/
â””â”€â”€ main.ts
```

### Por que essa Arquitetura?

**SeparaÃ§Ã£o por MÃ³dulos (Feature-based)**
- âœ… Cada mÃ³dulo Ã© **independente**: produtos, categorias, auditoria podem evoluir separado
- âœ… **Escalabilidade**: Novo desenvolvedor trabalha em `modules/products` sem afetar `modules/categories`
- âœ… **Testabilidade**: Cada mÃ³dulo tem seus testes, sem dependencies cruzadas

**Dentro de cada MÃ³dulo: CQRS**
```
products/
â”œâ”€â”€ commands/              # OperaÃ§Ãµes de escrita (CREATE, UPDATE, DELETE)
â”‚   â”œâ”€â”€ create-product.command.ts
â”‚   â””â”€â”€ handlers/
â”‚       â””â”€â”€ create-product.handler.ts
â”œâ”€â”€ queries/               # OperaÃ§Ãµes de leitura (GET, LIST, FILTER)
â”‚   â”œâ”€â”€ get-products.query.ts
â”‚   â””â”€â”€ handlers/
â”‚       â””â”€â”€ get-products.handler.ts
â”œâ”€â”€ entities/              # Domain model (com regras de negÃ³cio)
â”œâ”€â”€ repositories/          # Database access
â”œâ”€â”€ controllers/           # HTTP endpoints
â””â”€â”€ products.module.ts     # Exports pÃºblicos
```

**Por que CQRS aqui?**
- âœ… **IntenÃ§Ã£o clara**: `CreateProductCommand` vs `GetProductByIdQuery` â†’ explÃ­cito o que cada um faz
- âœ… **ValidaÃ§Ã£o centralizada**: Commands tÃªm validaÃ§Ã£o + eventos, Queries sÃ£o apenas leitura
- âœ… **Escalabilidade futura**: Pode-se cachear Queries independente de Commands

**Compartilhado em `shared/`**
- `events/` â†’ Domain events que podem ser reutilizados (ProductCreated, AttributeAdded, etc)
- `database/` â†’ ConexÃ£o PostgreSQL (compartilhada por todos modules)
- `logging/` â†’ Winston logger (centralizado)
- `config/` â†’ VariÃ¡veis de ambiente (um Ãºnico source of truth)

**Por que nÃ£o colocar tudo em `services/`?**
- âŒ Menos escalÃ¡vel: Um `ProductService` com 20 mÃ©todos Ã© difÃ­cil de manter
- âŒ Acoplamento: MudanÃ§a no ProductService afeta todo o app
- âŒ Menos testÃ¡vel: DifÃ­cil testar isoladamente

## ğŸš¨ Erros Comuns

| Erro | SoluÃ§Ã£o |
|------|---------|
| Port 5433 in use | Mudar porta no .env |
| PostgreSQL connection refused | `docker-compose up -d postgres` |
| Kafka topics empty | Aguarde 10s + verify brokers |

## âš–ï¸ Trade-offs Justificados

### Kafka
| Ganho | Perda |
|-------|-------|
| âœ… Durabilidade: Eventos persistem indefinidamente | âŒ Complexidade: Extra componente para gerenciar |
| âœ… Event Sourcing: HistÃ³rico completo de eventos | âŒ LatÃªncia: Auditoria Ã© assÃ­ncrona (nÃ£o imediata) |
| âœ… Escalabilidade: MÃºltiplos consumers em paralelo | âŒ Infraestrutura: Precisa de Kafka rodando |
| âœ… Desacoplamento: Producer nÃ£o depende de consumer | âŒ Debugging: Rastreamento de eventos mais complexo |

**Trade-off AceitÃ¡vel:** LatÃªncia assÃ­ncrona compensa por durabilidade e escalabilidade (specs pediam exatamente isso)

### CQRS
| Ganho | Perda |
|-------|-------|
| âœ… SeparaÃ§Ã£o: Commands vs Queries bem distintas | âŒ Verbosidade: Mais cÃ³digo para estruturar |
| âœ… Escalabilidade: Read e Write separados | âŒ Eventual Consistency: Dados podem nÃ£o ser imediatos |
| âœ… Clareza: IntenÃ§Ã£o explÃ­cita em cada operaÃ§Ã£o | âŒ Curva de aprendizado: Conceito menos comum |
| âœ… Performance: Queries podem ser cacheadas | âŒ Complexidade: Mais layers na arquitetura |

**Trade-off AceitÃ¡vel:** Verbosidade compensa por clareza e escalabilidade futura

### DDD
| Ganho | Perda |
|-------|-------|
| âœ… Regras centralizadas: BusinessRules em um lugar | âŒ Estrutura: Mais pastas e organizaÃ§Ãµes |
| âœ… Linguagem ubÃ­qua: Termos do negÃ³cio no cÃ³digo | âŒ Setup inicial: Mais boilerplate |
| âœ… Agregates: Entidades bem definidas e protegidas | âŒ Verbosidade: Value Objects e Entities extras |
| âœ… Testabilidade: LÃ³gica isolada e pura | âŒ Overhead: Para projetos pequenos pode ser excessivo |

**Trade-off AceitÃ¡vel:** Overhead inicial compensa por manutenibilidade long-term (specs pediam validaÃ§Ãµes complexas)

### PostgreSQL + TypeORM
| Ganho | Perda |
|-------|-------|
| âœ… ACID: TransaÃ§Ãµes confiÃ¡veis | âŒ Performance: SQL Ã© mais lento que NoSQL em alguns casos |
| âœ… Relacionamentos: Foreign keys mantÃªm integridade | âŒ Escalabilidade: Vertical (sharding Ã© complexo) |
| âœ… TypeORM: Type-safe queries | âŒ Rigidez: Schema fixo, mudanÃ§as custosas |

**Trade-off AceitÃ¡vel:** Rigidez compensa por integridade de dados (specs pediam relacionamentos)

### Testes E2E com Jest
| Ganho | Perda |
|-------|-------|
| âœ… Cobertura real: Testa toda stack (DB + API) | âŒ LentidÃ£o: Testes sÃ£o mais lentos (~20s) |
| âœ… ConfianÃ§a: Simula uso real da aplicaÃ§Ã£o | âŒ Setup: Precisa de Docker (postgres, kafka) |
| âœ… DetecÃ§Ã£o: Pega erros de integraÃ§Ã£o | âŒ Maintenance: Testes precisam update quando specs mudam |

**Trade-off AceitÃ¡vel:** LentidÃ£o compensa por confianÃ§a (35/35 tests = zero regressions)

## ğŸ“ Suporte

DÃºvidas? Abra uma issue ou check a documentaÃ§Ã£o Swagger.

---

**Stack:** NestJS 11 â€¢ TypeScript 5 â€¢ PostgreSQL 15 â€¢ Kafka 7.5 â€¢ TypeORM 0.3

**PadrÃµes:** CQRS â€¢ DDD â€¢ Event Sourcing â€¢ Clean Architecture
